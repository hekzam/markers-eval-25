# Hekzam Markers - Optimisation des marqueurs pour la correction d'examens

## Description du projet

Hekzam est un ensemble de logiciels conÃ§u pour permettre la crÃ©ation et la correction automatisÃ©e ou semi-automatisÃ©e des examens papier.  
Actuellement, Hekzam utilise des **QR codes** comme marqueurs de bord pour la calibration et l'identification des pages des copies d'examen. Cependant, ces marqueurs prÃ©sentent plusieurs inconvÃ©nients :

- **CoÃ»t Ã©levÃ© en encre** : les QR codes sont denses et nÃ©cessitent une quantitÃ© importante d'encre.
- **Espace occupÃ© important** : ils rÃ©duisent la place disponible pour le contenu pÃ©dagogique.
- **Consommation de ressources computationnelles** : leur gÃ©nÃ©ration et leur reconnaissance demandent un traitement relativement lourd.

### Objectif du projet

L'objectif de ce projet est de **dÃ©velopper et Ã©valuer des alternatives aux QR codes** utilisÃ©es actuellement dans Hekzam.  
Les nouvelles solutions devront Ãªtre plus sobres en encre et en espace tout en maintenant une **grande robustesse** dans leur dÃ©tection.

## DÃ©pendances nÃ©cessaires

Avant de compiler et d'exÃ©cuter le projet, installez les dÃ©pendances suivantes :

```sh
sudo apt-get install cmake ninja-build libopencv-dev nlohmann-json3-dev snapd
sudo snap install typst
```

- `cmake` : Outil de gÃ©nÃ©ration de build.
- `ninja-build` : SystÃ¨me de compilation rapide.
- `libopencv-dev` : BibliothÃ¨que de traitement dâ€™image pour lâ€™alignement et la reconnaissance des marqueurs.
- `nlohmann-json3-dev` : Gestion du format JSON pour la structuration des donnÃ©es.
- `snapd` & `typst` : GÃ©nÃ©ration des formulaires d'examen via Typst.
- `libzbar-dev` & `libzbar0` : si vous souhaitez utiliser zbar pour la dÃ©tection des QR codes au lieu de ZXing.

## Compilation du projet

Une fois les dÃ©pendances installÃ©es, compilez le projet avec :

```sh
cmake -H. -Bbuild-cmake -GNinja -DCMAKE_BUILD_TYPE=Release
cmake --build build-cmake -j
```

- `-H.` : SpÃ©cifie le rÃ©pertoire source.
- `-Bbuild-cmake` : DÃ©finit le rÃ©pertoire de build.
- `-GNinja` : Utilisation de Ninja comme gÃ©nÃ©rateur de build.
- `-DCMAKE_BUILD_TYPE=Release` : Compilation optimisÃ©e.
- `-DENABLE_ZBAR=ON` : si vous souhaitez utiliser zbar pour la dÃ©tection des QR codes au lieu de ZXing.

## ğŸ“„ GÃ©nÃ©ration de copie

Une fois la compilation terminÃ©e, utilisez la commande suivante pour gÃ©nÃ©rer les copies :

```sh
./create-copie.sh [options]
```

Ce script permet de produire une copie vers le dossier de sortie **copies/**.

### Options disponibles

```
  --encoded-size N      : Taille des marqueurs encodÃ©s (par dÃ©faut: 15)
  --unencoded-size N     : Taille des marqueurs non encodÃ©s (par dÃ©faut: 3)
  --header-size N       : Taille du marqueur d'entÃªte (par dÃ©faut: 7)
  --stroke-width N      : Largeur du trait des marqueurs (par dÃ©faut: 2)
  --margin N            : Marge autour des marqueurs (par dÃ©faut: 3)
  --grey-level N        : Niveau de gris (0: noir, 255: blanc) (par dÃ©faut: 0)
  --dpi N               : RÃ©solution en points par pouce (par dÃ©faut: 300)
  --generating-content BOOL : GÃ©nÃ©rer le contenu dans le document (1/true ou 0/false) (par dÃ©faut: 1)
  --filename NAME       : Nom du fichier de sortie (par dÃ©faut: copy)
  
  Options de configuration personnalisÃ©e des marqueurs:
  --tl TYPE             : Type de marqueur pour le coin supÃ©rieur gauche
  --tr TYPE             : Type de marqueur pour le coin supÃ©rieur droit
  --bl TYPE             : Type de marqueur pour le coin infÃ©rieur gauche
  --br TYPE             : Type de marqueur pour le coin infÃ©rieur droit
  --header TYPE         : Type de marqueur pour l'en-tÃªte

  Format des types de marqueurs: type[:encoded][:outlined]
  - type:outlined     : Marqueur non rempli (Ne fonctionne que pour les formes gÃ©omÃ©triques simples)
  - type:encoded      : Marqueur avec donnÃ©es encodÃ©es
  - type:unencoded    : Marqueur sans donnÃ©es encodÃ©es
```

Exemple avec une configuration complÃ¨te personnalisÃ©e:
```sh
./create-copie.sh --tl circle:outlined --tr circle:outlined --bl none --br qrcode:encoded --header qrcode:encoded --encoded-size 20 --unencoded-size 12 --grey-level 80 --header-size 18 --dpi 600 --filename exam_high_res
```

### Marqueurs disponibles

| Encodable       | Non encodable     | Rectangulaire    |
|-----------------|-------------------|------------------|
| qrcode          | circle            | pdf417           |
| micro-qr        | square            | rmqr             |
| datamatrix      | triangle          | code128          |
| aztec           | cross             |                  |
| pdf417          | aruco             |                  |
| rmqr            | qr-eye            |                  |
| code128         | custom            |                  |

## ğŸ“Š ExÃ©cution du benchmark

Vous pouvez exÃ©cuter l'outil de benchmark pour Ã©valuer les performances des diffÃ©rentes configurations de marqueurs :

```sh
./run_benchmark.sh [options]
```

### Benchmarks disponibles

Le systÃ¨me propose plusieurs types de benchmarks, sÃ©lectionnables avec l'option `--benchmark` :

- `parsing-time` : Ã‰value les performances d'analyse et de dÃ©tection des marqueurs
- `generation-time` : Ã‰value les performances de gÃ©nÃ©ration des copies (par dÃ©faut)
- `ink-estimation` : Estime la consommation d'encre pour diffÃ©rentes configurations de marqueurs

### Options en ligne de commande

Vous pouvez passer les paramÃ¨tres directement en ligne de commande :

```sh
./run_benchmark.sh --benchmark ink-estimation --input-dir=./copies --dpi=600
```

Options communes :
- `--benchmark=<type>` : Type de benchmark Ã  exÃ©cuter (parsing-time, generation-time, ink-estimation)
- `--output-dir=<path>` : RÃ©pertoire de sortie pour les rÃ©sultats
- `--input-dir=<path>` : RÃ©pertoire contenant les images d'entrÃ©e
- `--encoded-marker_size=<N>` : Taille des marqueurs encodÃ©s en mm
- `--unencoded-marker_size=<N>` : Taille des marqueurs non encodÃ©s en mm
- `--header-marker_size=<N>` : Taille du marqueur d'en-tÃªte en mm
- `--grey-level=<0-255>` : Niveau de gris pour les marqueurs
- `--dpi=<N>` : RÃ©solution en points par pouce

Options spÃ©cifiques pour les benchmarks de performance :
- `--nb-copies=<N>` : Nombre de copies Ã  gÃ©nÃ©rer pour le test
- `--warmup-iterations=<N>` : Nombre d'itÃ©rations d'Ã©chauffement avant la mesure
- `--atomic-boxes-file=<path>` : Fichier JSON contenant les dÃ©finitions des zones

### RÃ©sultats des benchmarks

#### Benchmark de temps de traitement

Le benchmark `parsing-time` produit des rÃ©sultats sur le temps de traitement et le taux de succÃ¨s de la dÃ©tection des marqueurs. Il gÃ©nÃ¨re les fichiers suivants dans le rÃ©pertoire de sortie :
- **Images calibrÃ©es** : Versions redressÃ©es des copies avec les zones dÃ©tectÃ©es
- **CSV de rÃ©sultats** : Fichier `benchmark_results.csv` avec les temps d'exÃ©cution et taux de succÃ¨s
- **Images de dÃ©bogage** (mode DEBUG uniquement) : Visualisation du processus de dÃ©tection

#### Benchmark d'estimation d'encre

Le benchmark `ink-estimation` analyse la consommation d'encre et affiche :
- Dimensions de l'image et rÃ©solution
- Surface totale couverte en cmÂ²
- Couverture d'encre moyenne en pourcentage
- Volume d'encre estimÃ© en millilitres
- Facteur de calibration utilisÃ©

#### Benchmark de temps de gÃ©nÃ©ration de copies
Le benchmark `generation-time` Ã©value le temps de gÃ©nÃ©ration des copies. Il gÃ©nÃ¨re un fichier CSV avec les rÃ©sultats de chaque itÃ©ration.

L'option `--warmup-iterations` est particuliÃ¨rement utile pour obtenir des mesures plus prÃ©cises. Les itÃ©rations d'Ã©chauffement exÃ©cutent le mÃªme code que les itÃ©rations de mesure, mais leurs rÃ©sultats ne sont pas comptabilisÃ©s dans les statistiques finales. Cela permet d'Ã©viter que les coÃ»ts de dÃ©marrage (chargement initial des bibliothÃ¨ques, initialisation des caches, etc.) n'affectent les mesures de performance.

### RÃ©sultats du benchmark

AprÃ¨s l'exÃ©cution, le benchmark produit plusieurs types de sorties :

- **Images calibrÃ©es** : Versions redressÃ©es des copies scannÃ©es avec les zones dÃ©tectÃ©es surlignÃ©es
- **CSV de rÃ©sultats** : Fichier `benchmark_results.csv` contenant les temps d'exÃ©cution et taux de succÃ¨s pour chaque image
- **Images de dÃ©bogage** (si compilÃ© en mode DEBUG) : Visualisation du processus de dÃ©tection des marqueurs

Le fichier CSV contient trois colonnes:
- **File**: Nom du fichier traitÃ©
- **Time(ms)**: Temps d'exÃ©cution en millisecondes
- **Success**: Indique si la dÃ©tection des marqueurs a rÃ©ussi (1) ou Ã©chouÃ© (0)

Ces donnÃ©es vous permettent d'analyser:
- Le taux de succÃ¨s global de la dÃ©tection pour chaque configuration de marqueurs
- Le temps moyen de traitement
- L'impact des diffÃ©rents paramÃ¨tres (taille, niveau de gris, etc.) sur les performances

Les images calibrÃ©es montrent les zones dÃ©tectÃ©es avec les codes couleur suivants:
- **Rose**: Zones utilisateur (zones de rÃ©ponse)
- **Bleu**: Marqueurs de coin
- **Vert**: Centre des marqueurs de coin

## ğŸ“‚ Structure du projet

```
.
â”œâ”€â”€ include/            # Fichiers d'en-tÃªte (*.h, *.hpp)
â”‚   â”œâ”€â”€ benchmark.hpp   # En-tÃªtes pour le benchmarking
â”‚   â””â”€â”€ common.h        # DÃ©finitions de structures communes
â”œâ”€â”€ src/                # Code source C++ principal
â”‚   â”œâ”€â”€ bench/          # Code source des benchmarks
â”‚   â”œâ”€â”€ benchmark.cpp   # Outil de benchmarking
â”‚   â”œâ”€â”€ expl_pars.cpp   # Parseur principal
â”‚   â”œâ”€â”€ typst_interface.cpp # Interface avec Typst
â”‚   â”œâ”€â”€ utils/          # Utilitaires partagÃ©s
â”‚   â”œâ”€â”€ parser/         # ImplÃ©mentation des parseurs de marqueurs
â”‚   â””â”€â”€ external-tools/ # Outils externes (crÃ©ation de copies)
â”œâ”€â”€ typst/              # Sources de templates Typst
â”‚   â”œâ”€â”€ components/     # Composants rÃ©utilisables (marqueurs, conteneurs)
â”‚   â”œâ”€â”€ common/         # Variables et utilitaires communs
â”‚   â”œâ”€â”€ content/        # Contenu des formulaires
â”‚   â”œâ”€â”€ src/            # Scripts de gÃ©nÃ©ration
â”‚   â”œâ”€â”€ style/          # Configuration de style
â”‚   â””â”€â”€ template.typ    # Template principal
â”œâ”€â”€ stats-analysis/     # Scripts et outils d'analyse statistique
â”œâ”€â”€ copies/             # Dossier de sortie pour les copies gÃ©nÃ©rÃ©es
â”œâ”€â”€ output/             # Dossier de sortie pour les rÃ©sultats d'analyse
â”œâ”€â”€ build-cmake/        # RÃ©pertoire de build (gÃ©nÃ©rÃ©)
â”œâ”€â”€ CMakeLists.txt      # Configuration du projet CMake
â”œâ”€â”€ create-copie.sh     # Script de gÃ©nÃ©ration de copies
â”œâ”€â”€ run_benchmark.sh    # Script d'exÃ©cution du benchmark
â”œâ”€â”€ README.md           # Ce fichier
â””â”€â”€ LICENSE             # Fichier de licence
```

## ğŸ“– RÃ©fÃ©rences techniques

- **OpenCV** : [https://opencv.org/](https://opencv.org/)
- **Typst** : [https://typst.app/](https://typst.app/)
- **ZXing** : [https://github.com/zxing/zxing](https://github.com/zxing/zxing)

## âš–ï¸ License

- Code: Apache-2.0
- Everything else, in particular documentation and measurements: CC-BY-SA-4.0
